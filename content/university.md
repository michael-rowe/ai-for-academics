# Generative AI in the university

The [Russell Group principles](https://russellgroup.ac.uk/media/6137/rg_ai_principles-final.pdf) on the use of generative AI in higher education was the first position statement I was aware of in the context of higher education.

1. Universities will support students and staff to become AI-literate.
2. Staff should be equipped to support students to use generative AI tools effectively and appropriately in their learning experience.
3. Universities will adapt teaching and assessment to incorporate the ethical use of generative AI and support equal access.
4. Universities will ensure academic rigour and integrity is upheld.
5. Universities will work collaboratively to share best practice as the technology and its application in education evolves.

As far as sets of principles go, this isn't a bad attempt to capture a high-level overview of what we should be aiming for.

However, it may be that principles like these don't go far enough. Maybe, they only go as far as is necessary for institutions to protect the status quo. For example, in [Helen Beetham's review](https://helenbeetham.substack.com/p/ai-literacy-and-schrodingers-ethics) of the Russell Group principles, she notes: 

> ...knowledge is not empowerment without the power to act, and resources to act with.

From my perspective, I'm not convinced that institutional policies will have the effect of helping students and staff develop AI-literacy and skills.

Which is why I think it's important to focus our attention at a more granular level i.e. in the [classroom](./classroom-policy.md). 